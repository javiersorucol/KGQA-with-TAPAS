{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d221f324-505a-4d86-965a-2731b5fe3137",
   "metadata": {},
   "source": [
    "# Entity extractor\n",
    "We will use this notebook to extra the found entities from QALD-json questions and store them under the linked entities key.\n",
    "To achive this we will work from the train and test QALD9 subsets, this subsets organized the questions into simple and complex (simple being questions that require only one triple in the SPARQL query), as the main goal of extracting the linked entities is to measure the quality of an entity linker, we will focus only in the simple questions. \n",
    "\n",
    "Let's import the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41a454c4-9fbc-45ed-be31-3f000d95d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_json(filename):\n",
    "    with open(filename, 'r', encoding=\"utf8\") as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def save_json(filename, data):\n",
    "    with open(filename, 'w', encoding=\"utf8\") as f:\n",
    "        json.dump(data, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4db59bab-0ed1-4dc4-abf5-be64f3f6029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subsets = read_json('../datasets/train_subsets.json')\n",
    "test_subsets = read_json('../datasets/test_subsets.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee63848-b96d-47fc-a7c6-fc9ec9c04e4b",
   "metadata": {},
   "source": [
    "Now let's create a function to add to a question the linked entities, we will try it with the following example question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d094b949-28a0-4529-9b7e-ecc2931bf074",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_question = {\n",
    "                \"id\": \"86\",\n",
    "                \"question\": [\n",
    "                    {\n",
    "                        \"language\": \"en\",\n",
    "                        \"string\": \"What is the highest mountain in Germany?\"\n",
    "                    }\n",
    "                ],\n",
    "                \"query\": {\n",
    "                    \"sparql\": \"PREFIX wdt: <http://www.wikidata.org/prop/direct/> PREFIX wd: <http://www.wikidata.org/entity/> SELECT ?uri WHERE { ?uri wdt:P31 wd:Q8502 ; wdt:P2044 ?elevation ; wdt:P17 wd:Q183 . } ORDER BY DESC(?elevation) LIMIT 1\"\n",
    "                },\n",
    "                \"answers\": [\n",
    "                    {\n",
    "                        \"head\": {\n",
    "                            \"vars\": [\n",
    "                                \"uri\"\n",
    "                            ]\n",
    "                        },\n",
    "                        \"results\": {\n",
    "                            \"bindings\": [\n",
    "                                {\n",
    "                                    \"uri\": {\n",
    "                                        \"type\": \"uri\",\n",
    "                                        \"value\": \"http://www.wikidata.org/entity/Q3375\"\n",
    "                                    }\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "225bba82-7411-4759-8023-b192720d8c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#def extract_linked_entities_from_question(question:dict):\n",
    "#    try:\n",
    "#        sparql = question.get('query').get('sparql')\n",
    "#        where_queries = re.findall(r'WHERE\\s?{.+}', sparql, re.I)\n",
    "#        triples = []\n",
    "#        entities = []\n",
    "#        \n",
    "#        for where_query in where_queries:\n",
    "#            where_query = re.findall(r'{.+}', where_query, re.I)[0][1:-1]\n",
    "#            triples = triples + re.split(r'\\.|;', where_query)\n",
    "        \n",
    "#        triples = list(filter(lambda x: 'wdt:P31 ' not in x, triples))\n",
    "#        for triple in triples:\n",
    "#            entities = entities + [ x.replace('wd:', '') for x in re.findall('wd:Q\\d+', triple) ]\n",
    "#            entities = entities + [ x.replace('<http://www.wikidata.org/entity/', '').replace('>','') for x in re.findall('<http:\\/\\/www\\.wikidata\\.org\\/entity\\/Q\\d+>', triple) ]\n",
    "        \n",
    "#        return list(set(entities))\n",
    "    \n",
    "#    except:\n",
    "#        print(question)\n",
    "def extract_linked_entities_from_question(question:dict):\n",
    "    try:\n",
    "        sparql = question.get('query').get('sparql')\n",
    "        prefix_entities = [ x.replace('wd:', '') for x in re.findall('wd:Q\\d+', sparql) ]\n",
    "        uri_entities = [ x.replace('<http://www.wikidata.org/entity/', '').replace('>','') for x in re.findall('<http:\\/\\/www\\.wikidata\\.org\\/entity\\/Q\\d+>', sparql) ]\n",
    "        return list(set(prefix_entities + uri_entities))\n",
    "    except:\n",
    "        print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6f3b0046-39d8-48d4-91c5-8748cfc48f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Q8502', 'Q183']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_linked_entities_from_question(example_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b902c124-8063-496a-9c68-cc7cc5f43fe1",
   "metadata": {},
   "source": [
    "Now lets apply this to all the simple questions subsets (singular, boolean, multiple and aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bd825746-1d08-43e7-b259-1be8a17a2f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_linked_entities_to_dataset(dataset:dict):\n",
    "    def apply_to_subset(subset):\n",
    "        for question in subset:\n",
    "            question['linked_entities'] = extract_linked_entities_from_question(question)\n",
    "        return subset\n",
    "    \n",
    "    for key, value in dataset.get('simple').items():\n",
    "        dataset['simple'][key] = apply_to_subset(value)\n",
    "        \n",
    "    return dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e4397833-88fb-4a84-ab13-f08b60b366b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test_subsets = add_linked_entities_to_dataset(test_subsets)\n",
    "result_train_subsets = add_linked_entities_to_dataset(train_subsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1e9889-8e7d-4601-b640-4aa1b0404573",
   "metadata": {},
   "source": [
    "Let's save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "83a25cee-47ad-45ac-b9a9-a714a2e4a996",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json('../datasets/train_subsets.json', result_train_subsets)\n",
    "save_json('../datasets/test_subsets.json', result_test_subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db3d8bc-8c5d-47f1-b33c-51bedd53c918",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
